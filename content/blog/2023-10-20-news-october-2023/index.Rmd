---
title: 'rOpenSci News Digest, October 2023'
author: 'The rOpenSci Team'
date: '2023-10-20'
tags:
  - newsletter
slug: news-october-2023
description: Dev guide translation to Portuguese, R in government community call, multilingualism community call, coworking, new packages and package news
params:
  last_newsletter: "2023-09-22"
---


```{r setup, include=FALSE}
library("magrittr")
library("rlang")
last_newsletter <- anytime::anytime(params$last_newsletter)
knitr::opts_chunk$set(echo = FALSE)
url <- sprintf(
    "/blog/%s/%s/%s/%s",
    lubridate::year(rmarkdown::yaml_front_matter(knitr::current_input())$date),
    stringr::str_pad(lubridate::month(rmarkdown::yaml_front_matter(knitr::current_input())$date), 2, "0", side = "left"),
    stringr::str_pad(lubridate::day(rmarkdown::yaml_front_matter(knitr::current_input())$date), 2, "0", side = "left"),
    rmarkdown::yaml_front_matter(knitr::current_input())$slug
    )
english <- function(x) {
  as.character(english::english(x))
}

nice_string <- function(...) {
  glue::glue_collapse(..., sep = ", ", last = ", and ")
}
```
<!-- Before sending DELETE THE INDEX_CACHE and re-knit! -->

Dear rOpenSci friends, it's time for our monthly news roundup!
<!-- blabla -->
You can read this post [on our blog](`r url`).
Now let's dive into the activity at and around rOpenSci!

## rOpenSci HQ

### Help us translate our dev guide to Portuguese

Since last year we started the translation and localization of our Spanish version of our [comprehensive guide to software development](https://devguide.ropensci.org/). We have a [first version in Spanish](https://devdevguide.netlify.app/es/preface.es.html) and now, thanks to the R Community initiative, we are working on the Portuguese version.

Our process includes the review of automatic translations by two people, and we need your help! 

If you are interested in collaborating with this community effort, please check the "TODO - Second Review" tab of [this project on GitHub](https://github.com/orgs/ropensci/projects/7) and let us know you want to collaborate by leaving a comment in the corresponding Pull Request.

All contributors will be added to the rOpenSci Slack, [listed on our multilingual publishing project webpage](/multilingual-publishing/) and acknowledged as authors of the Portuguese translation.

### Coworking

Read [all about coworking](/blog/2023/06/21/coworking/) in our recent [post](/blog/2023/06/21/coworking/)!

Join us for social coworking & office hours monthly on first Tuesdays! 
Hosted by Steffi LaZerte and various community hosts. 
Everyone welcome. 
No RSVP needed. 
Consult our [Events](/events) page to find your local time and how to join.

- [Tuesday, Nov 7th, 9:00 America Pacific (17:00 UTC)](/events/coworking-2023-11/), Fixing scary bugs üò±üêõ With community host [Salix Dubois](/author/salix-dubois/) and [Steffi LaZerte](/author/steffi-lazerte/).
    - Identify/fix some scary bugs;
    - Chat with Salix about scary bugs!

And remember, you can always cowork independently on work related to R, work on packages that tend to be neglected, or work on what ever you need to get done!


### Reminder: Three upcoming community calls, and our first one in Spanish!

#### [R in Government](/commcalls/oct2023-government/)

In this community call, our panelists will share their experiences and examples of projects with R at different levels of government and in different countries.
We invite you to learn about the challenges and lessons learned from our panelists and attendees in their efforts to make their government data, processes, and analyses more open and reproducible. 

With [Lu√≠za Andrade](https://ropensci.org/author/lu%C3%ADza-andrade/), [Karly Harker](https://ropensci.org/author/karly-harker/), [Ahmadou Dicko](https://ropensci.org/author/ahmadou-dicko/), [Pablo Tiscornia](https://ropensci.org/author/pablo-tiscornia/). 

**Tuesday, 31 October 2023 16:00 UTC** 

#### Multilingual Publishing

As global movements, Open Source and Open Science face language-based exclusion as most resources are in English. This affects scientists and research software engineers working in R, particularly those who don‚Äôt have English as their first language.

rOpenSci multilingual efforts aim to lower access barriers, democratize quality resources, and increase the possibilities of contributing to open software and science. We successfully piloted our Spanish-language peer review and the localization to Spanish of our comprehensive guide to software development, with Portuguese translation underway.

[Ma√´lle Salmon](/author/ma%C3%ABlle-salmon/), [Paola Corrales](/author/paola-corrales/), and [Elio Campitelli](/author/elio-campitelli/),  will share the rOpenSci Multilingual project details on this call. Ma√´lle will present the R packages that allow us to have our content in several languages. Then Elio and Paola will share the translation workflow and show the Translation Guide written to document the process.

- [**Multilingual Publishing**:  Tuesday, 21 November 2023 12:00 UTC](/commcalls/nov2023-multilingual/).

- [**Proyecto Multiling√ºe**: Thursday, 23 November 2023 12:00 UTC](/commcalls/nov2023-multilenguaje/).


## Software :package:: new versions

```{r new-packages, cache = TRUE, eval=TRUE}
cran_unquote <- function(string) {
  gsub("\\'(.*?)\\'", "\\1", string)
}
tidy_package <- function(entry) {
  tibble::tibble(
    package = entry$name,
    description = cran_unquote(entry$description),
    details = cran_unquote(entry$details),
    on_cran = entry$on_cran,
    on_bioc = entry$on_bioc,
    onboarding = entry$onboarding,
    url = entry$url,
    maintainer = entry$maintainer # use desc for more info
    
  )
}

registry <- "https://raw.githubusercontent.com/ropensci/roregistry/gh-pages/registry.json" %>%
  jsonlite::read_json() %>%
  purrr::pluck("packages") %>%
  purrr::map_df(tidy_package)
  
since <- lubridate::as_date(last_newsletter) - 1
until <- lubridate::as_date(last_newsletter) + 1
commits <- gh::gh(
  "GET /repos/{owner}/{repo}/commits",
  owner = "ropensci",
  repo = "roregistry",
  since = sprintf(
    "%s-%s-%sT00:00:00Z",
    lubridate::year(since),
    stringr::str_pad(lubridate::month(since), 2, "0", side = "left"),
    stringr::str_pad(lubridate::day(since), 2, "0", side = "left")
  ),
  until = sprintf(
    "%s-%s-%sT00:00:00Z",
    lubridate::year(until),
    stringr::str_pad(lubridate::month(until), 2, "0", side = "left"),
    stringr::str_pad(lubridate::day(until), 2, "0", side = "left")
  )
)

empty <- TRUE
i <- length(commits)
while (empty == TRUE) {
  old <- "https://raw.githubusercontent.com/ropensci/roregistry/%s/packages.json" %>%
    sprintf(commits[[i]]$sha) %>%
    jsonlite::read_json() %>%
    purrr::map_df(function(x) tibble::tibble(package = x$package, url = x$url, branch = x$branch))
  i <- i - 1
  if (nrow(old) > 100) {
    empty <- FALSE
  }
}

old <- dplyr::filter(
  old,
  !grepl("ropenscilabs\\/", url),
  !grepl("ropensci-archive\\/", url)
)

new <- dplyr::filter(
  registry,
  !package %in% old$package,
  !grepl("ropenscilabs\\/", url),
  !grepl("ropensci-archive\\/", url)
)
```

```{r, results='asis', cache = TRUE, eval=FALSE}
packages <- split(new, seq(nrow(new)))
present_one <- function(package) {
  if (package$package == "natserv") return(NULL)
  url_parts <- urltools::url_parse(package$url)
  desc_link <- gh::gh(
    "/repos/{owner}/{repo}/contents/{path}",
    owner = strsplit(url_parts$path, "\\/")[[1]][1],
    repo = strsplit(url_parts$path, "\\/")[[1]][2],
    path = "DESCRIPTION"
  ) %>%
    purrr::pluck("download_url")
  withr::with_tempfile(
    "tf", {
      download.file(desc_link, tf) 
      desc <<- desc::desc(file = tf)
    }
  )
  # as in pkgdown
  authors <- unclass(desc$get_authors())
  aut <- purrr::keep(authors, function(x) {any( x$role %in% "aut") && all(x$role != "cre") })
  aut <- purrr::map_chr(aut, function(x) paste(x$given, x$family))
  rev <- purrr::keep(authors, function(x) {any( x$role %in% "rev") && all(x$role != "cre") })
  rev <- purrr::map_chr(rev, function(x) paste(x$given, x$family))
  maintainer <- purrr::keep(authors, function(x) {any( x$role %in% "cre") })
  maintainer <- paste(c(maintainer[[1]]$given, maintainer[[1]]$family), collapse = " ")
  
  author_string <- sprintf("developed by %s", maintainer)
  
  if (length(aut) > 0) {
    author_string <- paste0(author_string, sprintf(" together with %s", nice_string(aut)))
  } 
  
  string <- sprintf(
    "[%s](https://docs.ropensci.org/%s), %s: %s. ",
    package$package, 
    package$package, 
    author_string,
    stringr::str_remove(stringr::str_squish(package$details), "\\.$")
  )
  
  if (package$on_cran) {
    string <- paste0(
      string, 
      sprintf(
        " It is available on [CRAN]( https://CRAN.R-project.org/package=%s). ",
        package$package
      )
    )
  }
  if (package$on_bioc) {
    string <- paste0(
      string, sprintf(
        " It is available on [Bioconductor](https://bioconductor.org/packages/%s/). ",
        package$package
      )
    )
  }
  if (nzchar(package$onboarding)) {
    string <- paste0(string, sprintf("It has been [reviewed](%s)", package$onboarding))
    if (length(rev) > 0) {
      string <- paste0(string, sprintf(" by %s.", nice_string(rev)))
    } else {
      string <- paste0(string, ".")
    }
  }
  
  paste("+", string)

}
text <- purrr::map(
  packages,
  present_one
) %>%
  purrr::compact() %>%
  unlist()
cat(paste0(text, collapse = "\n\n"))
```

```{r news, cache=TRUE}
registry <- dplyr::filter(
  registry,
  !grepl("ropenscilabs\\/", url),
  !grepl("ropensci-archive\\/", url)
)

registry <- registry %>%
  dplyr::rowwise() %>%
  dplyr::mutate(
  owner = strsplit(urltools::path(url), "/")[[1]][1],
  repo = strsplit(urltools::path(url), "/")[[1]][2]
) %>%
  dplyr::filter(
    !is.na(owner)
  )
packages <- split(registry, seq(nrow(registry)))
get_release <- function(repo) {
  info <- gh::gh(
    "GET /repos/{owner}/{repo}/releases",
    owner = repo$owner,
    repo = repo$repo,
    per_page = 3
  )
  info <- info[!purrr::map_lgl(info, "draft")]
  if(length(info) == 0 || anytime::anytime(info[[1]]$published_at) < last_newsletter) {
    return(NULL)
  }
  
  tibble::tibble(
    package = repo$package,
    version = info[[1]]$tag_name,
    url = info[[1]]$html_url,
    description = repo$description
  )
}
packages[purrr::map_chr(packages, "package") == "gert"][[1]]$owner <- "r-lib"
packages[purrr::map_chr(packages, "package") == "gert"][[1]]$repo <- "gert"
packages[purrr::map_chr(packages, "package") == "credentials"][[1]]$owner <- "r-lib"
packages[purrr::map_chr(packages, "package") == "credentials"][[1]]$repo <- "credentials"
packages[purrr::map_chr(packages, "package") == "commonmark"][[1]]$owner <- "r-lib"
packages[purrr::map_chr(packages, "package") == "commonmark"][[1]]$repo <- "commonmark"
releases <- purrr::map_df(
  packages,
  get_release
)
releases <- split(releases, seq(nrow(releases)))
format_release <- function(release) {
  sprintf(
    '[%s](https://docs.ropensci.org/%s "%s") ([`%s`](%s))',
    release$package,
    release$package,
    release$description,
    release$version,
    release$url
  )
}
all_releases <- purrr::map_chr(releases, format_release)
text <- nice_string(all_releases)
```

The following `r if (length(releases) > 1) english(length(releases))` package`r if (length(releases) > 1) "s"` `r if (length(releases) > 1) "have" else "has"` had an update since the last newsletter: `r text`.

## Software Peer Review

```{r software-review, results='asis'}
# from pkgdown https://github.com/r-lib/pkgdown/blob/1ca166905f1b019ed4af9642617ea09fa2b8fc17/R/utils.r#L176

get_description <- function(body) {
  lines <- strsplit(body, "\n")[[1]]
  name <- stringr::str_squish(sub("Package:", "", lines[grepl("^Package", lines)][1]))
  description <- stringr::str_squish(sub("Title:", "", lines[grepl("^Title", lines)][1]))
  description <- cran_unquote(sub("\\.$", "", description))
  list(name = name, description = description)
}

get_user_text <- function(issue) {
  info <- gh::gh("GET /users/{username}", username = issue$user$login)
  name <- info$name %||% issue$user$login
  url <- if (nzchar(info$blog)) info$blog else info$html_url
  if (!grepl("^https?:", url)) url <- paste0("http://", url)
  sprintf("[%s](%s)", name, url)
  
}

tidy_issue <- function(issue) {
  labels <- purrr::map_chr(issue$labels, "name")
  label <- labels[grepl("[0-9]\\/.*", labels)][1]
  df <- tibble::tibble(
    label = label,
    name = get_description(issue$body)$name,
    description = get_description(issue$body)$description,
    title = issue$title,
    holding = "holding" %in% purrr::map_chr(issue$labels, "name"),
    others = toString(purrr::map_chr(issue$labels, "name")),
    closed_at = issue$closed_at %||% NA,
    url = issue$html_url,
    user = get_user_text(issue),
    stats = dplyr::if_else("stats" %in% purrr::map_chr(issue$labels, "name"), " (Stats).", "")
  )
  
  dplyr::rowwise(df) %>%
    dplyr::mutate(text = sprintf("    * [%s](%s), %s. Submitted by %s. %s", name, url, description, user, stats))
}

get_issues <- function(label, state) {
  issues <- gh::gh(
    "GET /repos/{owner}/{repo}/issues",
    owner = "ropensci",
    repo = "software-review",
    state = state, 
    labels = label
  )
  
  purrr::map_df(issues, tidy_issue)
}
  
active_issues <- purrr::map_df(
  c("1/editor-checks","2/seeking-reviewer(s)","3/reviewer(s)-assigned","4/review(s)-in-awaiting-changes","5/awaiting-reviewer(s)-response","6/approved"),
  get_issues,
  state = "open"
)

closed_issues <- get_issues(state = "closed", label  ="6/approved")

ok_date <- function(date) {
  if (is.na(date)) {
    return(TRUE)
  } 
  
  anytime::anytime(date) >= last_newsletter
}

closed_issues <- dplyr::rowwise(closed_issues) %>%
  dplyr::filter(ok_date(closed_at))

issues <- dplyr::bind_rows(active_issues, closed_issues)


no_holding <- sum(issues$holding)
issues <- dplyr::filter(issues, !holding)
text <- sprintf("There are %s recently closed and active submissions", english(nrow(issues)))
if (no_holding > 0) {
  text <- paste0(
    text,
    sprintf(
      " and %s submission%s on hold.",
      no_holding,
      if (no_holding > 1) "s" else ""
    )
  )
} else {
  text <- paste0(text, ".")
}

count_label <- function(label) {
  no <- snakecase::to_sentence_case(english(sum(issues$label == label, na.rm = TRUE)))
  url <- paste0("https://github.com/ropensci/software-review/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc+label%3A", label)
  sprintf("* %s at ['%s'](%s):\n\n %s", no, label, url, paste0(issues$text[!is.na(issues$label)][ issues$label == label], collapse = "\n\n"))
}

cat(text)
cat(
  paste0(
    " Issues are at different stages: \n\n",
    paste0(
      purrr::map_chr(sort(unique(issues$label[!is.na(issues$label)]), decreasing = TRUE), count_label),
      collapse = "\n\n"
    )
  )
)
```

Find out more about [Software Peer Review](/software-review) and how to get involved.

## On the blog

<!-- Do not forget to rebase your branch! -->

```{r blog}

parse_one_post <- function(path){
  lines <- suppressWarnings(readLines(path, encoding = "UTF-8"))
  yaml <- blogdown:::split_yaml_body(lines)$yaml
  yaml <- glue::glue_collapse(yaml, sep = "\n")
  yaml <- yaml::yaml.load(yaml)
  
  language <- function(path) {
    name <- fs::path_ext_remove(fs::path_file(path))
    if (grepl("\\.[a-z][a-z]", name)) {
      sub(".*\\.", "", name)
    } else {
      "en"
    }
  }
  software_peer_review <- "Software Peer Review" %in% yaml$tags
  tech_note <- "tech notes" %in% yaml$tags && !software_peer_review
  other <- !software_peer_review && !tech_note
  
  
  meta <- tibble::tibble(
    date = anytime::anydate(yaml$date),
    author = nice_string(yaml$author),
    title = yaml$title,
    software_peer_review = software_peer_review,
    tech_note = tech_note,
    other = other,
    socialImg = yaml$socialImg %||% "",
    socialAlt = yaml$socialAlt %||% "",
    description = stringr::str_squish(yaml$description %||% ""),
    newsletter = "newsletter" %in% yaml$tags,
    slug = yaml$slug,
    dir = fs::path_dir(path),
    language = language(path)
    )

  post_url <- if (meta[["language"]] == "en") {
    sprintf(
      "/blog/%s/%s/%s/%s",
      lubridate::year(meta$date),
      stringr::str_pad(lubridate::month(meta$date), 2, "0", side = "left"),
      stringr::str_pad(lubridate::day(meta$date), 2, "0", side = "left"),
      meta$slug
    )
  } else {
    sprintf(
      "/%s/blog/%s/%s/%s/%s",
      meta[["language"]],
      lubridate::year(meta$date),
      stringr::str_pad(lubridate::month(meta$date), 2, "0", side = "left"),
      stringr::str_pad(lubridate::day(meta$date), 2, "0", side = "left"),
      meta$slug
    )
  }

  meta$url <- post_url
  meta
}
paths <- fs::dir_ls("..", recurse = TRUE, glob = "*.md")
paths <- paths[!paths %in% c("../_index.md", "../2021-02-03-targets/raw_data_source.md",
  "../2021-02-03-targets/README.md")]
posts <- purrr::map_df(paths, parse_one_post)
posts <- dplyr::filter(posts, date >= as.Date(last_newsletter), !newsletter)
posts <- split(posts, posts[["dir"]])
format_post <- function(dir) {
  main_language <- if (any(dir[["language"]] == "en")) {
    "en"
  } else {
    dir[["language"]][[1]]
  }
  
  post <- dir[which(dir[["language"]] == main_language),]
  string <- sprintf("* [%s](%s) by %s", post$title, post$url, post$author)
  if (post$description != "") {
    string <- paste0(string, ". ", sub("\\?$", "", sub("\\!$", "", sub("\\.$", "", post$description), ".")), ".")
  } else {
    string <- paste0(string, ".")  
  }
  
  if (post$socialImg != "") {
    img_file <- fs::path_file(post$socialImg)
    download.file(sprintf("https://ropensci.org/%s", post$socialImg), img_file)
    img_file %>% magick::image_read() %>% magick::image_scale("400x") %>% magick::image_write(img_file)
    string <- paste0(
      string,
      sprintf('{{< figure src="%s" alt="%s" width="400" >}}\n\n', img_file, post$socialAlt)
    )
  }
  
other_langs <- dir[which(dir[["language"]] != main_language),]
  other_langs <- split(other_langs, sort(as.numeric(rownames(other_langs))))
  if (length(other_langs) > 0) {
    other_langs_text <- purrr::map_chr(
      other_langs,
      ~ sprintf("<a href='%s' lang='%s'>%s (%s)</a>", .x[["url"]], .x[["language"]], .x[["title"]], .x[["language"]])
      ) %>% 
      toString
    other_langs_text <- sprintf("Other languages: %s.", other_langs_text)
    string <- sprintf("%s %s", string, other_langs_text)
  }
  
  string
}
```

```{r, results='asis'}
software_review <- posts[purrr::map_lgl(posts, ~any(.x[["software_peer_review"]]))]
if (length(software_review) > 0) {
  cat("### Software Review\n\n")
  cat(
    paste0(
      purrr::map_chr(software_review, format_post),
      collapse = "\n\n"
    )
  )
  cat("\n\n")
}

others <- posts[purrr::map_lgl(posts, ~any(.x[["other"]]))]
if (length(others) > 0) {
  cat(
    paste0(
      purrr::map_chr(others, format_post),
      collapse = "\n\n"
    )
  )
  cat("\n\n")
}


tech_notes <- posts[purrr::map_lgl(posts, ~any(.x[["tech_note"]]))]
if (length(tech_notes) > 0) {
  cat("\n\n")
  cat("### Tech Notes\n\n")
  cat(
    paste0(
      purrr::map_chr(tech_notes, format_post),
      collapse = "\n\n"
    )
  )
  cat("\n\n")
}
```

## Call for maintainers

If you're interested in maintaining any of the R packages below, you might enjoy reading our blog post [What Does It Mean to Maintain a Package?](/blog/2023/02/07/what-does-it-mean-to-maintain-a-package/) (or listening to its discussion on the [R Weekly highlights podcast](https://rweekly.fireside.fm/111) hosted by Eric Nantz and Mike Thomas)!

- **[rvertnet](https://cran.r-project.org/web/packages/rvertnet/index.html)**, Retrieve, map and summarize data from the VertNet.org archives (<https://vertnet.org/>). Functions allow searching by many parameters, including taxonomic names, places, and dates. In addition, there is an interface for conducting spatially delimited searches, and another for requesting large datasets via email. [Issue for volunteering](https://github.com/ropensci-archive/rvertnet/issues/71).

### Call for co-maintainers

Refer to our somewhat [recent blog post](/blog/2022/10/17/maintain-or-co-maintain-an-ropensci-package/#packages-looking-for-co-maintainers) to identify other packages where help is especially wished for!
See also our [help wanted page](/help-wanted/) -- before opening a PR, we recommend asking in the issue whether help is still needed.

## Package development corner

Some useful tips for R package developers. :eyes:

### System Dependencies in R Packages & Automatic Testing

Are you curious about, or stalled by, the installation of system dependencies in your continuous integration workflows?
Refer to [Hugo Gruson's clear and extensive post](https://blog.r-hub.io/2023/09/26/system-dependency/) on the R-hub blog.

### Translate your package's messages with {potools}

The [potools](https://michaelchirico.github.io/potools/) package by Michael Chirico is to translation files what roxygen2 is to Rd documentation files: it very much simplifies your writing and maintaining them!
Refer to [potools documentation](https://michaelchirico.github.io/potools/) or a recent [tutorial](https://masalmon.eu/2023/10/06/potools-mwe/).


### testthat new release

If you use testthat for your package tests, don't miss the [release announcement](https://www.tidyverse.org/blog/2023/10/testthat-3-2-0/) of testthat 3.2.0!
That post describes the major features such as the return of mocking support within testthat itself.

Among [minor features](https://testthat.r-lib.org/news/index.html#minor-features-and-bug-fixes-3-2-0) you might notice the new `desc` argument of `testthat::test_file()` to run a single test at a time.
You can now for instance run `devtools::test_active_file(desc = 'blop() runs')`


## Last words

Thanks for reading! If you want to get involved with rOpenSci, check out our [Contributing Guide](https://contributing.ropensci.org) that can help direct you to the right place, whether you want to make code contributions, non-code contributions, or contribute in other ways like sharing use cases.

If you haven't subscribed to our newsletter yet, you can [do so via a form](/news/). Until it's time for our next newsletter, you can keep in touch with us via our [website](/) and [Mastodon account](https://hachyderm.io/@rOpenSci).
