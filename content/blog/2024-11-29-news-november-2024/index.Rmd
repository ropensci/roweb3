---
slug: "news-november-2024"
title: rOpenSci News Digest, November 2024
author:
  - The rOpenSci Team
date: '2024-11-29'
tags:
  - newsletter
description: Support first-time contributors, fast R-universe, give thanks to contributors
params:
  last_newsletter: "2024-10-23"
---

```{r setup, include=FALSE}
library("magrittr")
library("rlang")
last_newsletter <- anytime::anytime(params$last_newsletter)
knitr::opts_chunk$set(echo = FALSE)
url <- sprintf(
    "/blog/%s/%s/%s/%s",
    lubridate::year(rmarkdown::yaml_front_matter(knitr::current_input())$date),
    stringr::str_pad(lubridate::month(rmarkdown::yaml_front_matter(knitr::current_input())$date), 2, "0", side = "left"),
    stringr::str_pad(lubridate::day(rmarkdown::yaml_front_matter(knitr::current_input())$date), 2, "0", side = "left"),
    rmarkdown::yaml_front_matter(knitr::current_input())$slug
    )
english <- function(x) {
  as.character(english::english(x))
}

nice_string <- function(...) {
  if (length(...) == 2) {
    return(paste(c(...), collapse = " and "))
  }
  glue::glue_collapse(..., sep = ", ", last = ", and ")
}
```
<!-- Before sending DELETE THE INDEX_CACHE and re-knit! -->

Dear rOpenSci friends, it's time for our monthly news roundup!
<!-- blabla -->
You can read this post [on our blog](`r url`).
Now let's dive into the activity at and around rOpenSci!

## rOpenSci HQ
### Looking for Maintainers to Support First-Time Contributors

**Now open to non-rOpenSci package maintainers!**

Making your first contribution to Open Source can be both empowering and intimidating. As such, we‚Äôre exited to announce a special series of activities to support first-time contributors! üéâ

Are you an package maintainer who would like to help someone make their first contribution? We limited our initial call to rOpenSci package maintainers, but we still have some room, so have decided to open this up to all package maintainers!

See our [blog post](/blog/2024/10/22/first-time-contributions/) for more details and how to sign up (by December 9th).
### A fast R-Universe!

Thanks to optimized caching, the web front-end pages load much faster, making it even more fun to [browse around the R ecosystem](https://r-universe.dev/search).

### Yanina Bellini Saibene's keynote talk at CarpentryConnect and BioNT 2024 

In her keynote Yanina Bellini Saibene invited the audience to reflect on how to measure the impact of our work in our communities. 
She shared two frameworks we use at rOpenSci and severals tool to measure different aspects of our work and our impact, not only with numbers, but with stories.
[Slidedeck](https://yabellini.netlify.app/talk/2024_carpentryconbiont/).


###  Tradu√ß√£o + Hackathon = Traslat√≥n rOpenSci

We had a very nice and productive event during [LatinR](/events/latinr-2024/), with people registered from thirteen countries. 
Some people stayed for the whole event and others participated during some of the working sessions.
 
We discussed the [GitHub workflow](/blog/2023/09/26/how-to-translate-a-hugo-blog-post-with-babeldown/) and the [babelquarto](https://docs.ropensci.org/babelquarto/) and [babeldown](https://docs.ropensci.org/babeldown/) packages. 
We also reviewed the [translation guidelines](https://translationguide.ropensci.org/) and started working on a Portuguese glossary for the translations.

Participants worked on reviewing the rOpenSci [dev guide](https://devdevguide.netlify.app/pt/index.pt.html). 
As a result, we now have two more chapters with their first review started, two chapters with the second review under work, and five chapters merged with the complete translation. We also started the translation of our Code of Conduct.  üöÄ 

We are very grateful to Pedro Faria, Beatriz Milz, Francesca Palmeira, Rafael Fontenelle, Ildeberto Vasconcelos,  Samuel Carleial, and Ariana Cabral for their contributions during the Traslat√≥n üôè.

 If you want to participate in this collaborative translation effort, please [check out our project](https://github.com/orgs/ropensci/projects/7/views/1) and add a comment to the pull request you would like to review.
 
### Community Call "A comunidade R fala portugu√™s" Resources
 
 All the [resources for our first community call in portugu√™s](/commcalls/translation-portuguese/) are now available on our website.
 
 Check the video, speakers slides, and links to other resources related to translation efforts in the R Community.

### Give Thanks with the allcontributors Package

Mark Padgham published a [blog post](/blog/2024/11/26/allcontributors/) about his [allcontributors package](https://docs.ropensci.org/allcontributors/), which provides a very easy way to acknowledge all contributions to your software.
  
     
### Coworking

Join us for [social coworking & office hours](/blog/2023/06/21/coworking/) monthly on first Tuesdays! 
Hosted by Steffi LaZerte and various community hosts. 
Everyone welcome. 
No RSVP needed. 
Consult our [Events](/events) page to find your local time and how to join.

- [Tuesday, December 3rd, 09:00 Australia Western (01:00 UTC)](/events/coworking-2024-12), "Getting Involved in the Antarctic/Southern Ocean rOpenSci Community" with cohosts [Michael Sumner](/author/michael-sumner ) and [Ben Raymond](/author/ben-raymond), and [Steffi LaZerte](/author/steffi-lazerte).
    - [Explore rOpenSci R packages](/blog/2018/11/13/antarctic/#demo) supporting Antarctic and Southern Ocean Research.
    - Chat with our cohosts to find out how you can be involved in this community.
    
- [Tuesday, January 14th, 14:00 European Central (13:00 UTC)](/events/coworking-2025-01/), "Working with Parquet in R" with cohosts [Rainer M Krug](/author/rainer-m-krug/), and [Steffi LaZerte](/author/steffi-lazerte).
    - Read up on what Parquet is.
    - Explore how to use Parquet in R.
    - Meet community host, Rainer Krug, and discuss benefits and tips for using Parquet in R and how you might use it in your work.

And remember, you can always cowork independently on work related to R, work on packages that tend to be neglected, or work on what ever you need to get done!

## Software :package:


```{r new-packages, cache = TRUE}
cran_unquote <- function(string) {
  gsub("\\'(.*?)\\'", "\\1", string)
}
tidy_package <- function(entry) {
  tibble::tibble(
    package = entry$name,
    description = cran_unquote(entry$description),
    details = cran_unquote(entry$details),
    on_cran = entry$on_cran,
    on_bioc = entry$on_bioc,
    onboarding = entry$onboarding,
    url = entry$url,
    maintainer = entry$maintainer # use desc for more info
    
  )
}

registry <- "https://raw.githubusercontent.com/ropensci/roregistry/gh-pages/registry.json" %>%
  jsonlite::read_json() %>%
  purrr::pluck("packages") %>%
  purrr::map_df(tidy_package)
  
since <- lubridate::as_date(last_newsletter) - 1
until <- lubridate::as_date(last_newsletter) + 1
commits <- gh::gh(
  "GET /repos/{owner}/{repo}/commits",
  owner = "ropensci",
  repo = "roregistry",
  since = sprintf(
    "%s-%s-%sT00:00:00Z",
    lubridate::year(since),
    stringr::str_pad(lubridate::month(since), 2, "0", side = "left"),
    stringr::str_pad(lubridate::day(since), 2, "0", side = "left")
  ),
  until = sprintf(
    "%s-%s-%sT00:00:00Z",
    lubridate::year(until),
    stringr::str_pad(lubridate::month(until), 2, "0", side = "left"),
    stringr::str_pad(lubridate::day(until), 2, "0", side = "left")
  )
)

empty <- TRUE
i <- length(commits)
while (empty == TRUE) {
  old <- "https://raw.githubusercontent.com/ropensci/roregistry/%s/packages.json" %>%
    sprintf(commits[[i]]$sha) %>%
    jsonlite::read_json() %>%
    purrr::map_df(function(x) tibble::tibble(package = x$package, url = x$url, branch = x$branch))
  i <- i - 1
  if (nrow(old) > 100) {
    empty <- FALSE
  }
}

old <- dplyr::filter(
  old,
  !grepl("ropenscilabs\\/", url),
  !grepl("ropensci-archive\\/", url)
)

new <- dplyr::filter(
  registry,
  !package %in% old$package,
  !grepl("ropenscilabs\\/", url),
  !grepl("ropensci-archive\\/", url)
)
```


```{r, results='asis', cache = TRUE,eval=FALSE}
packages <- split(new, seq(nrow(new)))
present_one <- function(package) {
  url_parts <- urltools::url_parse(package$url)
  desc_link <- gh::gh(
    "/repos/{owner}/{repo}/contents/{path}",
    owner = strsplit(url_parts$path, "\\/")[[1]][1],
    repo = strsplit(url_parts$path, "\\/")[[1]][2],
    path = "DESCRIPTION"
  ) %>%
    purrr::pluck("download_url")
  
  if (package$package == "eDNAjoint") {
    desc_link <- "https://raw.githubusercontent.com/ropensci/eDNAjoint/26fb2d22dcd4314cdf7d170812c6247ae51f25a0/DESCRIPTION"
  }
  
  withr::with_tempfile(
    "tf", {
      download.file(desc_link, tf) 
      desc <<- desc::desc(file = tf)
    }
  )
  # as in pkgdown
  authors <- unclass(desc$get_authors())
  aut <- purrr::keep(authors, function(x) {any( x$role %in% "aut") && all(x$role != "cre") })
  aut <- purrr::map_chr(aut, function(x) paste(x$given, x$family))
  rev <- purrr::keep(authors, function(x) {any( x$role %in% "rev") && all(x$role != "cre") })
  rev <- purrr::map_chr(rev, function(x) paste(x$given, x$family))
  maintainer <- purrr::keep(authors, function(x) {any( x$role %in% "cre") })
  maintainer <- paste(c(maintainer[[1]]$given, maintainer[[1]]$family), collapse = " ")
  author_string <- sprintf("developed by %s", maintainer)
  
  if (length(aut) > 0) {
    author_string <- paste0(author_string, sprintf(" together with %s", nice_string(aut)))
  } 
  
  string <- sprintf(
    "[%s](https://docs.ropensci.org/%s), %s: %s. ",
    package$package, 
    package$package, 
    author_string,
    stringr::str_remove(stringr::str_squish(package$details), "\\.$")
  )
  
  if (package$on_cran) {
    string <- paste0(
      string, 
      sprintf(
        " It is available on [CRAN]( https://CRAN.R-project.org/package=%s). ",
        package$package
      )
    )
  }
  if (package$on_bioc) {
    string <- paste0(
      string, sprintf(
        " It is available on [Bioconductor](https://bioconductor.org/packages/%s/). ",
        package$package
      )
    )
  }
  if (nzchar(package$onboarding)) {
    string <- paste0(string, sprintf("It has been [reviewed](%s)", package$onboarding))
    if (package$package == "karel") {
      rev <- c("Veronica Jimenez-Jacinto", "Joel Nitta")
    }
    if (length(rev) > 0) {
      string <- paste0(string, sprintf(" by %s.", nice_string(rev)))
    } else {
      string <- paste0(string, ".")
    }
  }
  
  paste("+", string)

}
text <- purrr::map_chr(
  packages,
  present_one
)
cat(paste0(text, collapse = "\n\n"))
```

Discover [more packages](/packages), read more about [Software Peer Review](/software-review).

### New versions

```{r news, cache=TRUE}
registry <- dplyr::filter(
  registry,
  !grepl("ropenscilabs\\/", url),
  !grepl("ropensci-archive\\/", url)
)

registry <- registry %>%
  dplyr::rowwise() %>%
  dplyr::mutate(
  owner = strsplit(urltools::path(url), "/")[[1]][1],
  repo = strsplit(urltools::path(url), "/")[[1]][2]
) %>%
  dplyr::filter(
    !is.na(owner)
  )
packages <- split(registry, seq(nrow(registry)))
get_release <- function(repo) {
  info <- gh::gh(
    "GET /repos/{owner}/{repo}/releases",
    owner = repo$owner,
    repo = repo$repo,
    per_page = 3,
    description = repo$description
  )
  info <- info[!purrr::map_lgl(info, "draft")]
  if(length(info) == 0 || anytime::anytime(info[[1]]$published_at) < last_newsletter) {
    return(NULL)
  }
  
  tibble::tibble(
    package = repo$package,
    version = info[[1]]$tag_name,
    url = info[[1]]$html_url,
    description = repo$description
  )
}
releases <- purrr::map_df(
  packages,
  get_release
)
releases <- split(releases, seq(nrow(releases)))
format_release <- function(release) {
  sprintf(
    '[%s](https://docs.ropensci.org/%s "%s") ([`%s`](%s))',
    release$package,
    release$package,
    release$description,
    release$version,
    release$url
  )
}
all_releases <- purrr::map_chr(releases, format_release)
text <- nice_string(all_releases)
```

The following `r if (length(releases) > 1) english(length(releases))` package`r if (length(releases) > 1) "s"` `r if (length(releases) > 1) "have" else "has"` had an update since the last newsletter: `r text`.

## Software Peer Review

```{r software-review, results='asis'}
# from pkgdown https://github.com/r-lib/pkgdown/blob/1ca166905f1b019ed4af9642617ea09fa2b8fc17/R/utils.r#L176

get_description <- function(body) {
  lines <- strsplit(body, "\n")[[1]]
  name <- stringr::str_squish(sub("Package:", "", lines[grepl("^Package", lines)][1]))
  description <- stringr::str_squish(sub("Title:", "", lines[grepl("^Title", lines)][1]))
  description <- cran_unquote(sub("\\.$", "", description))
  list(name = name, description = description)
}

get_user_text <- function(issue) {
  info <- gh::gh("GET /users/{username}", username = issue$user$login)
  name <- info$name %||% issue$user$login
  url <- if (nzchar(info$blog)) info$blog else info$html_url
  if (!grepl("^https?:", url)) url <- paste0("http://", url)
  sprintf("[%s](%s)", name, url)
  
}

tidy_issue <- function(issue) {
  labels <- purrr::map_chr(issue$labels, "name")
  label <- labels[grepl("[0-9]\\/.*", labels)][1]
  df <- tibble::tibble(
    label = label,
    name = get_description(issue$body)$name,
    description = get_description(issue$body)$description,
    title = issue$title,
    holding = "holding" %in% purrr::map_chr(issue$labels, "name"),
    others = toString(purrr::map_chr(issue$labels, "name")),
    closed_at = issue$closed_at %||% NA,
    url = issue$html_url,
    user = get_user_text(issue),
    stats = dplyr::if_else("stats" %in% purrr::map_chr(issue$labels, "name"), " (Stats).", "")
  )
  
  dplyr::rowwise(df) %>%
    dplyr::mutate(text = sprintf("    * [%s](%s), %s. Submitted by %s. %s", name, url, description, user, stats))
}

get_issues <- function(label, state) {
  issues <- gh::gh(
    "GET /repos/{owner}/{repo}/issues",
    owner = "ropensci",
    repo = "software-review",
    state = state, 
    labels = label
  )
  
  purrr::map_df(issues, tidy_issue)
}
  
active_issues <- purrr::map_df(
  c("1/editor-checks","2/seeking-reviewer(s)","3/reviewer(s)-assigned","4/review(s)-in-awaiting-changes","5/awaiting-reviewer(s)-response","6/approved"),
  get_issues,
  state = "open"
)

closed_issues <- get_issues(state = "closed", label  ="6/approved")

ok_date <- function(date) {
  if (is.na(date)) {
    return(TRUE)
  } 
  
  anytime::anytime(date) >= last_newsletter
}

closed_issues <- dplyr::rowwise(closed_issues) %>%
  dplyr::filter(ok_date(closed_at))

issues <- dplyr::bind_rows(active_issues, closed_issues)


no_holding <- sum(issues$holding)
issues <- dplyr::filter(issues, !holding)
text <- sprintf("There are %s recently closed and active submissions", english(nrow(issues)))
if (no_holding > 0) {
  text <- paste0(
    text,
    sprintf(
      " and %s submission%s on hold.",
      no_holding,
      if (no_holding > 1) "s" else ""
    )
  )
} else {
  text <- paste0(text, ".")
}

count_label <- function(label) {
  no <- snakecase::to_sentence_case(english(sum(issues$label == label, na.rm = TRUE)))
  url <- paste0("https://github.com/ropensci/software-review/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc+label%3A", label)
  sprintf("* %s at ['%s'](%s):\n\n %s", no, label, url, paste0(issues$text[!is.na(issues$label)][ issues$label == label], collapse = "\n\n"))
}

cat(text)
cat(
  paste0(
    " Issues are at different stages: \n\n",
    paste0(
      purrr::map_chr(sort(unique(issues$label[!is.na(issues$label)]), decreasing = TRUE), count_label),
      collapse = "\n\n"
    )
  )
)
```

Find out more about [Software Peer Review](/software-review) and how to get involved.

## On the blog

<!-- Do not forget to rebase your branch! -->

```{r blog}

parse_one_post <- function(path){
  lines <- suppressWarnings(readLines(path, encoding = "UTF-8"))
  yaml <- blogdown:::split_yaml_body(lines)$yaml
  yaml <- glue::glue_collapse(yaml, sep = "\n")
  yaml <- yaml::yaml.load(yaml)
  
  language <- function(path) {
    name <- fs::path_ext_remove(fs::path_file(path))
    if (grepl("\\.[a-z][a-z]", name)) {
      sub(".*\\.", "", name)
    } else {
      "en"
    }
  }

  
  meta <- tibble::tibble(
    date = anytime::anydate(yaml$date),
    author = nice_string(yaml$author),
    title = yaml$title,
    software_peer_review = "Software Peer Review" %in% yaml$tags,
    tech_note = "tech notes" %in% yaml$tags && !"Software Peer Review" %in% yaml$tags,
    other = !"tech notes" %in% yaml$tags && !"Software Peer Review" %in% yaml$tags,
    socialImg = yaml$socialImg %||% "",
    socialAlt = yaml$socialAlt %||% "",
    description = yaml$description %||% "",
    newsletter = "newsletter" %in% yaml$tags,
    slug = yaml$slug,
    dir = fs::path_dir(path),
    language = language(path)
    )

  post_url <- if (meta[["language"]] == "en") {
    sprintf(
      "/blog/%s/%s/%s/%s",
      lubridate::year(meta$date),
      stringr::str_pad(lubridate::month(meta$date), 2, "0", side = "left"),
      stringr::str_pad(lubridate::day(meta$date), 2, "0", side = "left"),
      meta$slug
    )
  } else {
    sprintf(
      "/%s/blog/%s/%s/%s/%s",
      meta[["language"]],
      lubridate::year(meta$date),
      stringr::str_pad(lubridate::month(meta$date), 2, "0", side = "left"),
      stringr::str_pad(lubridate::day(meta$date), 2, "0", side = "left"),
      meta$slug
    )
  }

  meta$url <- post_url
  meta
}
paths <- fs::dir_ls("..", recurse = TRUE, glob = "*.md")
paths <- paths[!paths %in% c("../_index.md",  "../2021-02-03-targets/raw_data_source.md",
  "../2021-02-03-targets/README.md")]
posts <- purrr::map_df(paths, parse_one_post)
posts <- dplyr::filter(posts, date >= as.Date(last_newsletter), !newsletter)
posts <- split(posts, posts[["dir"]])
format_post <- function(dir) {
  main_language <- if (any(dir[["language"]] == "en")) {
    "en"
  } else {
    dir[["language"]][[1]]
  }
  
  post <- dir[which(dir[["language"]] == main_language),]
  string <- sprintf("* [%s](%s) by %s", post$title, post$url, post$author)
  if (post$description != "") {
    string <- paste0(string, ". ", sub("\\?$", "", sub("\\!$", "", sub("\\.$", "", post$description), ".")), ".")
  } else {
    string <- paste0(string, ".")  
  }
  
  if (post$socialImg != "") {
    img_file <- fs::path_file(post$socialImg)
    download.file(sprintf("https://ropensci.org/%s", post$socialImg), img_file)
    img_file %>% magick::image_read() %>% magick::image_scale("400x") %>% magick::image_write(img_file)
    string <- paste0(
      string,
      sprintf('{{< figure src="%s" alt="%s" width="400" >}}\n\n', img_file, post$socialAlt)
    )
  }
  
other_langs <- dir[which(dir[["language"]] != main_language),]
  other_langs <- split(other_langs, sort(as.numeric(rownames(other_langs))))
  if (length(other_langs) > 0) {
    other_langs_text <- purrr::map_chr(
      other_langs,
      ~ sprintf("<a href='%s' lang='%s'>%s (%s)</a>", .x[["url"]], .x[["language"]], .x[["title"]], .x[["language"]])
      ) %>% 
      toString
    other_langs_text <- sprintf("Other languages: %s.", other_langs_text)
    string <- sprintf("%s %s", string, other_langs_text)
  }
  
  string
}
```

```{r, results='asis'}
software_review <- posts[purrr::map_lgl(posts, ~any(.x[["software_peer_review"]]))]
if (length(software_review) > 0) {
  cat("### Software Review\n\n")
  cat(
    paste0(
      purrr::map_chr(software_review, format_post),
      collapse = "\n\n"
    )
  )
  cat("\n\n")
}

others <- posts[purrr::map_lgl(posts, ~any(.x[["other"]]))]
if (length(others) > 0) {
  cat(
    paste0(
      purrr::map_chr(others, format_post),
      collapse = "\n\n"
    )
  )
  cat("\n\n")
}


tech_notes <- posts[purrr::map_lgl(posts, ~any(.x[["tech_note"]]))]
if (length(tech_notes) > 0) {
  cat("\n\n")
  cat("### Tech Notes\n\n")
  cat(
    paste0(
      purrr::map_chr(tech_notes, format_post),
      collapse = "\n\n"
    )
  )
  cat("\n\n")
}
```

## Calls for contributions

### Calls for maintainers

If you're interested in maintaining any of the R packages below, you might enjoy reading our blog post [What Does It Mean to Maintain a Package?](/blog/2023/02/07/what-does-it-mean-to-maintain-a-package/).

* [hddtools](https://docs.ropensci.org/hddtools/), Hydrological Data Discovery Tools. [Issue for volunteering](https://github.com/ropensci/hddtools/issues/36).

* [circle](https://docs.ropensci.org/circle/), R client package for the Continuous Integration (CI) provider Circle CI. [Issue for volunteering](https://github.com/ropensci/circle/issues/46).

* [tic](https://docs.ropensci.org/tic/), Tasks Integrating Continuously: CI-Agnostic Workflow Definitions. [Issue for volunteering](https://github.com/ropensci/tic/issues/339).

* [USAboundaries](https://docs.ropensci.org/USAboundaries/) (and USAboundariesdata), historical and contemporary boundaries of the United States of America . [Issue for volunteering](https://github.com/ropensci/USAboundaries/issues/50).

* [historydata](https://docs.ropensci.org/historydata/), datasets for historians. [Issue for volunteering](https://github.com/ropensci/historydata/issues/23).

### Calls for contributions

Refer to our [help wanted page](/help-wanted/) -- before opening a PR, we recommend asking in the issue whether help is still needed.

The bib2f package, for parsing BibTeX files into tibbles, would need some help! [Issue for volunteering](https://github.com/ropensci/bib2df/issues/65).

## Package development corner

Some useful tips for R package developers. :eyes:

### posit::conf(2024) session recordings

The recordings of talks at posit::conf(2024) are now available on [YouTube](https://www.youtube.com/playlist?list=PL9HYL-VRX0oSFkdF4fJeY63eGDvgofcbn).
Particularly relevant for package developers are:

- [Why‚Äôd you load that package for?](https://www.youtube.com/watch?v=q4vmmlUEoQg&list=PL9HYL-VRX0oSFkdF4fJeY63eGDvgofcbn&index=85) by Luis D. Verde Arregoitia.

- [Open-Source Initiatives in Pharma - What's Out There and Why You Should Join](https://www.youtube.com/watch?v=vdwBTbaRYOg&list=PL9HYL-VRX0oSFkdF4fJeY63eGDvgofcbn&index=93) by Nicholas Masel.

- [Art of R Packages: Forging Community with Hex Stickers](https://www.youtube.com/watch?v=Pw-wvDYD0Ks&list=PL9HYL-VRX0oSFkdF4fJeY63eGDvgofcbn&index=69) by Hubert Halun.

- [Introducing Positron, a new data science IDE](https://www.youtube.com/watch?v=8uRcB34Hhsw&list=PL9HYL-VRX0oSFkdF4fJeY63eGDvgofcbn&index=3) by Julia Silge, Isabel Zimmerman, Tom Mock, Jonathan McPherson, Lionel Henry, Davis Vaughan, and Jenny Bryan.

- [Contributing to the R Project](https://www.youtube.com/watch?v=gegeaoMSgzc&list=PL9HYL-VRX0oSFkdF4fJeY63eGDvgofcbn&index=38) by Heather Turner.

- [API-first package design ‚Äî and learning patchwork in the process](https://www.youtube.com/watch?v=mtUKYGvkXm8&list=PL9HYL-VRX0oSFkdF4fJeY63eGDvgofcbn&index=43) by Thomas Lin Pedersen.

- ["Please Let Me Merge Before I Start Crying": And Other Things I've Said at The Git Terminal](https://www.youtube.com/watch?v=y2qdvYKKVdc&list=PL9HYL-VRX0oSFkdF4fJeY63eGDvgofcbn&index=50) by Meghan Harris.

- [Mixing R, Python, and Quarto: Crafting the Perfect Open Source Cocktail](https://www.youtube.com/watch?v=8174mk6SGcU&list=PL9HYL-VRX0oSFkdF4fJeY63eGDvgofcbn&index=57) by Alenka Frim & Nic Crane.

... and more! Happy watching.

### API packages and CRAN

Don't miss the blog post [Handling CRAN Requirements for Web API R Packages](https://blog.thecoatlessprofessor.com/programming/r/api-packages-and-cran-requirements/) by James Balamuta!

Also relevant, this chapter of the HTTP testing in R book: [CRAN- (and Bioconductor) preparedness for your tests](https://books.ropensci.org/http-testing/cran-preparedness.html).

### Update your GitHub Actions workflow

If you were still using version 3 of the Artifacts action, upgrade as your workflows will start [failing](https://github.blog/changelog/2024-04-16-deprecation-notice-v3-of-the-artifact-actions/).
Thanks to Hugo Gruson for pointing this out!

A tip by Jacob Wujciak-Jens: Github provides the [dependabot service](https://docs.github.com/en/code-security/dependabot/working-with-dependabot/keeping-your-actions-up-to-date-with-dependabot) that can help you keep actions updated hassle free! Just add the following simple yaml file as `.github/dependabot.yml` in your repo and a friendly bot will open PRs to keep you workflows up to date!

```yaml
version: 2
updates:
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "monthly"
    open-pull-requests-limit: 10
```
### An attack vector on GitHub Actions

Thanks to Zhian Kamvar for bringing up the article ["ArtiPACKED: Hacking Giants Through a Race Condition in GitHub Actions Artifacts"](https://unit42.paloaltonetworks.com/github-repo-artifacts-leak-tokens/) in our slack workspace.
In Zhian's words: if you upload an artifact that contains the `.git/` directory of a cloned repo, the `GITHUB_TOKEN` is exposed. 
While it expires at the end of the run, there is a small delay, which is long enough for a targeted attack. 
The solution is to set `persist-credentials`: false for every `actions/checkout` run.

## Last words

Thanks for reading! If you want to get involved with rOpenSci, check out our [Contributing Guide](https://contributing.ropensci.org) that can help direct you to the right place, whether you want to make code contributions, non-code contributions, or contribute in other ways like sharing use cases.
You can also support our work through [donations](/donate).

If you haven't subscribed to our newsletter yet, you can [do so via a form](/news/). Until it's time for our next newsletter, you can keep in touch with us via our [website](/) and [Mastodon account](https://hachyderm.io/@rOpenSci).
