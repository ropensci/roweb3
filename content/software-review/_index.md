+++
title = "rOpenSci Software Peer Review"
description = "rOpenSci's open peer-review system of R packages"
+++

rOpenSci's [suite of packages](/packages/) is comprised of contributions from staff engineers and the wider R community, bringing considerable diversity of skills, expertise and experience to bear on the suite. How do we ensure that every package is held to a high standard? That's where our software review system comes into play: packages contributed by the community undergo a **transparent, constructive, non adversarial and open review process**. For that process relying mostly on **volunteer work**, _[associate editors](#editors)_ manage the incoming flow and ensure progress of submissions; _authors_ create, submit and improve their package; *[reviewers](https://devguide.ropensci.org/softwarereviewintro.html#reviewers)*, two per submission, examine the software code and user experience. Our system current accepts software from a variety of broadly-defined categories, with a [new project](/blog/2019/07/15/expanding-software-review/) underway to expand the software review system to include specifically [statistical software](/stat-software-review).

Technically, we make the most of [GitHub](https://github.com/) infrastructure: each package software peer review process is an issue in the [ropensci/software-review GitHub repository](https://github.com/ropensci/software-review/). For instance, read [the software peer review thread of the `ropenaq` package](https://github.com/ropensci/software-review/issues/24): the process is an ongoing conversation until acceptance of the package, with two external reviews as important milestones. Furthermore, we use GitHub features such as the use of issue templates (as submission templates), and labelling which we use to track progress of submissions (from editor checks to approval).
